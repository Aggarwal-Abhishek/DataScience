{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c83ef819",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-11T23:44:57.004264Z",
     "start_time": "2022-09-11T23:44:55.974903Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using: cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "from time import time\n",
    "\n",
    "SEED = 1234\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "import amazonDataset\n",
    "import twitterDataset\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "717d50d2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-11T23:44:57.008464Z",
     "start_time": "2022-09-11T23:44:57.005812Z"
    }
   },
   "outputs": [],
   "source": [
    "amazon_data_dir = '/home/abhishek/Downloads/datasets/kaggle/SentimentAnalysis/amazon/'\n",
    "twitter_dataset_path = '/home/abhishek/Downloads/datasets/kaggle/SentimentAnalysis/twitter/training.1600000.processed.noemoticon.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e698d38",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-11T23:45:18.498888Z",
     "start_time": "2022-09-11T23:44:57.009337Z"
    }
   },
   "outputs": [],
   "source": [
    "amazon_datasets = amazonDataset.AmazonDataset(os.path.join(amazon_data_dir, 'train.ft.txt')), \\\n",
    "                 amazonDataset.AmazonDataset(os.path.join(amazon_data_dir, 'test.ft.txt')), \n",
    "\n",
    "twitter_dataset = twitterDataset.ReadDF(twitter_dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fcdd932f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-11T23:45:27.847795Z",
     "start_time": "2022-09-11T23:45:18.499999Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'INIT': '[CLS]', 'EOS': '[SEP]', 'PAD': '[PAD]', 'UNK': '[UNK]'} {'INIT': 101, 'EOS': 102, 'PAD': 0, 'UNK': 100}\n",
      "512\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "TOKEN = {\n",
    "    \"INIT\": tokenizer.cls_token,\n",
    "    \"EOS\": tokenizer.sep_token,\n",
    "    \"PAD\": tokenizer.pad_token,\n",
    "    \"UNK\": tokenizer.unk_token\n",
    "}\n",
    "\n",
    "TOKEN_IDX = {\n",
    "    \"INIT\": tokenizer.cls_token_id,\n",
    "    \"EOS\": tokenizer.sep_token_id,\n",
    "    \"PAD\": tokenizer.pad_token_id,\n",
    "    \"UNK\": tokenizer.unk_token_id\n",
    "}\n",
    "print(TOKEN, TOKEN_IDX)\n",
    "\n",
    "max_input_length = tokenizer.max_model_input_sizes['bert-base-uncased']\n",
    "print(max_input_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03afc561",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-11T22:48:57.540748Z",
     "start_time": "2022-09-11T22:48:57.534330Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4393a5db",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-11T23:45:27.851313Z",
     "start_time": "2022-09-11T23:45:27.848431Z"
    }
   },
   "outputs": [],
   "source": [
    "def TextToToken(sentence):\n",
    "    tokens = tokenizer.tokenize(sentence)\n",
    "    tokens = tokens[:max_input_length-2]\n",
    "    indexed = [TOKEN_IDX['INIT']] + tokenizer.convert_tokens_to_ids(tokens) + [TOKEN_IDX['EOS']]\n",
    "    return indexed\n",
    "\n",
    "def BatchTextToTensor(sentences):\n",
    "    tokens = list(map(TextToToken, sentences))\n",
    "    max_length = max([len(x) for x in tokens])\n",
    "    token = map(lambda x: x + [TOKEN_IDX['PAD']]*(max_length-len(x)), list(tokens))\n",
    "    return torch.LongTensor(list(token))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66718a40",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-11T23:14:44.742877Z",
     "start_time": "2022-09-11T23:14:44.729471Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f77f760d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-11T23:45:27.859214Z",
     "start_time": "2022-09-11T23:45:27.851840Z"
    }
   },
   "outputs": [],
   "source": [
    "DATASET = torch.utils.data.ConcatDataset([*amazon_datasets, twitter_dataset])\n",
    "\n",
    "TRAIN_TEST_RATIO = 0.8\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "TRAIN_LEN = int(len(DATASET)*0.8)\n",
    "TEST_LEN = len(DATASET) - TRAIN_LEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "24a3a9d4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-11T23:45:28.287556Z",
     "start_time": "2022-09-11T23:45:27.859854Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120000, 30000)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data, test_data = torch.utils.data.random_split(DATASET, [TRAIN_LEN, TEST_LEN])\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, BATCH_SIZE, shuffle=False, num_workers=4)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, BATCH_SIZE, shuffle=False, num_workers=4)\n",
    "\n",
    "len(train_loader), len(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f344caf8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-11T23:45:28.289937Z",
     "start_time": "2022-09-11T23:45:28.288373Z"
    }
   },
   "outputs": [],
   "source": [
    "# bert, word2vec, glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6717fba8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-11T23:45:28.297877Z",
     "start_time": "2022-09-11T23:45:28.290525Z"
    }
   },
   "outputs": [],
   "source": [
    "# ***************** IMDB Dataset ******************** #\n",
    "\n",
    "# tokens = tokenizer.tokenize('Hello worLD how ArE YOU ? ')\n",
    "# indexes = tokenizer.convert_tokens_to_ids(tokens)\n",
    "# tokens, indexes\n",
    "\n",
    "\n",
    "# from torchtext.legacy import data\n",
    "# TEXT = data.Field(\n",
    "#     batch_first=True, use_vocab=False, tokenize=Tokenize, \n",
    "#     preprocessing=tokenizer.convert_tokens_to_ids,\n",
    "#     init_token=TOKEN_IDX['INIT'],\n",
    "#     eos_token=TOKEN_IDX['EOS'],\n",
    "#     pad_token=TOKEN_IDX['PAD'],\n",
    "#     unk_token=TOKEN_IDX['UNK']\n",
    "# )\n",
    "# LABEL = data.LabelField(dtype=torch.float)\n",
    "\n",
    "# from torchtext.legacy import datasets\n",
    "# train_data, test_data = datasets.IMDB.splits(TEXT, LABEL)\n",
    "\n",
    "# LABEL.build_vocab(train_data)\n",
    "\n",
    "# BATCH_SIZE = (64,64)\n",
    "# train_iterator, test_iterator = data.BucketIterator.splits(\n",
    "#     (train_data, test_data),\n",
    "#     batch_sizes=BATCH_SIZE,\n",
    "#     device=device\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "62003dee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-11T23:45:28.300659Z",
     "start_time": "2022-09-11T23:45:28.299189Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ba151c5b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-11T23:45:33.610580Z",
     "start_time": "2022-09-11T23:45:28.301290Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "bert = BertModel.from_pretrained('bert-base-uncased').to(device)\n",
    "for name, param in bert.named_parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "print(bert.config.to_dict()['hidden_size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9b43872d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-11T23:45:33.614832Z",
     "start_time": "2022-09-11T23:45:33.611247Z"
    }
   },
   "outputs": [],
   "source": [
    "class BertGruSentiment(nn.Module):\n",
    "    def __init__(self, hidden_dim, output_dim, n_layers, dropout):\n",
    "        super().__init__()\n",
    "        embedding_dim = bert.config.to_dict()['hidden_size']\n",
    "        self.rnn = nn.GRU(\n",
    "            embedding_dim, hidden_dim, \n",
    "            num_layers=n_layers, bidirectional=True, \n",
    "            batch_first=True, dropout=dropout\n",
    "        )\n",
    "        self.out = nn.Linear(hidden_dim*2, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, text):\n",
    "        with torch.no_grad():\n",
    "            embedded = bert(text)[0]\n",
    "        \n",
    "        _, hidden = self.rnn(embedded)\n",
    "        hidden = self.dropout(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim=1))\n",
    "        output = self.out(hidden)\n",
    "        return output\n",
    "    \n",
    "    def param_count(self):\n",
    "        return sum(p.numel() for p in self.parameters() if p.requires_grad)\n",
    "    def named_params(self):\n",
    "        return [x[0] for x in self.named_parameters() if x[1].requires_grad]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "90ecfe8a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-11T23:45:34.018960Z",
     "start_time": "2022-09-11T23:45:33.615420Z"
    }
   },
   "outputs": [],
   "source": [
    "HIDDEN_DIM = 256\n",
    "OUTPUT_DIM = 1\n",
    "N_LAYERS = 2\n",
    "DROPOUT = 0.5\n",
    "model = BertGruSentiment(HIDDEN_DIM, OUTPUT_DIM, N_LAYERS, DROPOUT).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3b299bbd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-11T23:45:34.021799Z",
     "start_time": "2022-09-11T23:45:34.019855Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "criterion = nn.BCEWithLogitsLoss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "13059721",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-11T23:45:34.029593Z",
     "start_time": "2022-09-11T23:45:34.022429Z"
    }
   },
   "outputs": [],
   "source": [
    "def accuracy(preds, actual):\n",
    "    rounded = torch.round(torch.sigmoid(preds))\n",
    "    correct = (rounded == actual)\n",
    "    return correct.sum() / len(correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "399646dd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-11T23:45:34.033320Z",
     "start_time": "2022-09-11T23:45:34.030138Z"
    }
   },
   "outputs": [],
   "source": [
    "def Train(epoch, print_every=100):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    start_time = time()\n",
    "    \n",
    "    model.train()\n",
    "    for idx, batch in enumerate(train_loader, 1):\n",
    "        optimizer.zero_grad()\n",
    "        batch[0] = BatchTextToTensor(batch[0]).to(device)\n",
    "        batch[1] = batch[1].float().to(device)\n",
    "        \n",
    "        predictions = model(batch[0]).squeeze(1)\n",
    "        \n",
    "        loss = criterion(predictions, batch[1])\n",
    "        acc = accuracy(predictions, batch[1])\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "        if idx%print_every == 0:\n",
    "            print('\\t[{}] [{}/{}], Loss: {:.3f}, Accuracy: {:.2f}, Time: {:.1f} minutes'.format(\n",
    "                epoch, idx, len(train_loader), loss.item(), acc.item(), (time()-start_time)/60\n",
    "            ))\n",
    "    epoch_acc /= len(train_loader)\n",
    "    epoch_loss /= len(train_loader)\n",
    "    print('Train Epoch: {} | Loss: {:.4f}, Accuracy: {:.2f} | Time: {:.1f} minutes'.format(\n",
    "        epoch, epoch_loss, epoch_acc, (time()-start_time)/60\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a6ea6f73",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-11T23:45:34.036910Z",
     "start_time": "2022-09-11T23:45:34.033901Z"
    }
   },
   "outputs": [],
   "source": [
    "def Test(epoch, print_every=100):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    start_time = time()\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for idx, batch in enumerate(test_loader, 1):\n",
    "            batch[0] = BatchTextToTensor(batch[0]).to(device)\n",
    "            batch[1] = batch[1].float().to(device)\n",
    "            \n",
    "            predictions = model(batch[0]).squeeze(1)\n",
    "            loss = criterion(predictions, batch[1])\n",
    "            acc = accuracy(predictions, batch[1])\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "            \n",
    "            if idx%print_every == 0:\n",
    "                print('\\t[{}] [{}/{}] Testing Completed, Time: {:.1f} minutes'.format(\n",
    "                    epoch, idx, len(test_loader), (time()-start_time)/60\n",
    "                ))\n",
    "    \n",
    "    epoch_acc /= len(test_loader)\n",
    "    epoch_loss /= len(test_loader)\n",
    "    print('Test Epoch: {} | Loss: {:.4f}, Accuracy: {:.2f} | Time: {:.1f} minutes'.format(\n",
    "        epoch, epoch_loss, epoch_acc, (time()-start_time)/60\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3a6b80ed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-12T00:09:01.113913Z",
     "start_time": "2022-09-11T23:45:34.037470Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[0] [1000/120000], Loss: 0.583, Accuracy: 0.70, Time: 3.4 minutes\n",
      "\t[0] [2000/120000], Loss: 0.436, Accuracy: 0.78, Time: 6.8 minutes\n",
      "\t[0] [3000/120000], Loss: 0.509, Accuracy: 0.75, Time: 10.1 minutes\n",
      "\t[0] [4000/120000], Loss: 0.402, Accuracy: 0.80, Time: 13.5 minutes\n",
      "\t[0] [5000/120000], Loss: 0.504, Accuracy: 0.78, Time: 16.9 minutes\n",
      "\t[0] [6000/120000], Loss: 0.535, Accuracy: 0.72, Time: 20.3 minutes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-3:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/abhishek/anaconda3/envs/abhienv/lib/python3.9/multiprocessing/process.py\", line 318, in _bootstrap\n",
      "    util._exit_function()\n",
      "  File \"/home/abhishek/anaconda3/envs/abhienv/lib/python3.9/multiprocessing/util.py\", line 360, in _exit_function\n",
      "    _run_finalizers()\n",
      "  File \"/home/abhishek/anaconda3/envs/abhienv/lib/python3.9/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/home/abhishek/anaconda3/envs/abhienv/lib/python3.9/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/home/abhishek/anaconda3/envs/abhienv/lib/python3.9/multiprocessing/queues.py\", line 201, in _finalize_join\n",
      "    thread.join()\n",
      "  File \"/home/abhishek/anaconda3/envs/abhienv/lib/python3.9/threading.py\", line 1053, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "  File \"/home/abhishek/anaconda3/envs/abhienv/lib/python3.9/threading.py\", line 1069, in _wait_for_tstate_lock\n",
      "    elif lock.acquire(block, timeout):\n",
      "KeyboardInterrupt\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f06494d3a60>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/abhishek/anaconda3/envs/abhienv/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/abhishek/anaconda3/envs/abhienv/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 1301, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/abhishek/anaconda3/envs/abhienv/lib/python3.9/multiprocessing/process.py\", line 149, in join\n",
      "    res = self._popen.wait(timeout)\n",
      "  File \"/home/abhishek/anaconda3/envs/abhienv/lib/python3.9/multiprocessing/popen_fork.py\", line 40, in wait\n",
      "    if not wait([self.sentinel], timeout):\n",
      "  File \"/home/abhishek/anaconda3/envs/abhienv/lib/python3.9/multiprocessing/connection.py\", line 936, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/home/abhishek/anaconda3/envs/abhienv/lib/python3.9/selectors.py\", line 416, in select\n",
      "    fd_event_list = self._selector.poll(timeout)\n",
      "  File \"/home/abhishek/anaconda3/envs/abhienv/lib/python3.9/site-packages/torch/utils/data/_utils/signal_handling.py\", line 66, in handler\n",
      "    _error_if_any_worker_fails()\n",
      "RuntimeError: DataLoader worker (pid 5779) exited unexpectedly with exit code 1. Details are lost due to multiprocessing. Rerunning with num_workers=0 may give better error trace.\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/abhishek/anaconda3/envs/abhienv/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3444, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_5720/1419694417.py\", line 2, in <module>\n",
      "    Train(epoch, 1000)\n",
      "  File \"/tmp/ipykernel_5720/2242097262.py\", line 20, in Train\n",
      "    epoch_loss += loss.item()\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/abhishek/anaconda3/envs/abhienv/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2064, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/abhishek/anaconda3/envs/abhienv/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/home/abhishek/anaconda3/envs/abhienv/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 248, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/abhishek/anaconda3/envs/abhienv/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/home/abhishek/anaconda3/envs/abhienv/lib/python3.9/inspect.py\", line 1541, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/home/abhishek/anaconda3/envs/abhienv/lib/python3.9/inspect.py\", line 1499, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/home/abhishek/anaconda3/envs/abhienv/lib/python3.9/inspect.py\", line 709, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/home/abhishek/anaconda3/envs/abhienv/lib/python3.9/inspect.py\", line 755, in getmodule\n",
      "    os.path.realpath(f)] = module.__name__\n",
      "  File \"/home/abhishek/anaconda3/envs/abhienv/lib/python3.9/posixpath.py\", line 392, in realpath\n",
      "    path, ok = _joinrealpath(filename[:0], filename, {})\n",
      "  File \"/home/abhishek/anaconda3/envs/abhienv/lib/python3.9/posixpath.py\", line 426, in _joinrealpath\n",
      "    if not islink(newpath):\n",
      "  File \"/home/abhishek/anaconda3/envs/abhienv/lib/python3.9/posixpath.py\", line 167, in islink\n",
      "    st = os.lstat(path)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_5720/1419694417.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mTrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mTest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_5720/2242097262.py\u001b[0m in \u001b[0;36mTrain\u001b[0;34m(epoch, print_every)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mepoch_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0mepoch_acc\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0macc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/abhienv/lib/python3.9/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2063\u001b[0m                         \u001b[0;31m# in the engines. This should return a list of strings.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2064\u001b[0;31m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2065\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'KeyboardInterrupt' object has no attribute '_render_traceback_'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/abhienv/lib/python3.9/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2064\u001b[0m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2065\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2066\u001b[0;31m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[0m\u001b[1;32m   2067\u001b[0m                                             value, tb, tb_offset=tb_offset)\n\u001b[1;32m   2068\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/abhienv/lib/python3.9/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1365\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1366\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1367\u001b[0;31m         return FormattedTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1368\u001b[0m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[1;32m   1369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/abhienv/lib/python3.9/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1265\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose_modes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1266\u001b[0m             \u001b[0;31m# Verbose modes need a full traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1267\u001b[0;31m             return VerboseTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1268\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1269\u001b[0m             )\n",
      "\u001b[0;32m~/anaconda3/envs/abhienv/lib/python3.9/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1122\u001b[0m         \u001b[0;34m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1124\u001b[0;31m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0m\u001b[1;32m   1125\u001b[0m                                                                tb_offset)\n\u001b[1;32m   1126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/abhienv/lib/python3.9/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1080\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1082\u001b[0;31m         \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m         \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/abhienv/lib/python3.9/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[0;34m(etype, value, records)\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[0;31m# first frame (from in to out) that looks different.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m     \u001b[0;31m# Select filename, lineno, func_name to track frames with\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "for epoch in range(1):\n",
    "    Train(epoch, 1000)\n",
    "    Test(epoch, 1000)\n",
    "    torch.save(model.state_dict(), f'model_{epoch}.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c810b96",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-12T00:09:01.115347Z",
     "start_time": "2022-09-12T00:09:01.115328Z"
    }
   },
   "outputs": [],
   "source": [
    "# model.load_state_dict(torch.load('model_2.pt'))\n",
    "# Test('test', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ecaefb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-12T00:09:01.116125Z",
     "start_time": "2022-09-12T00:09:01.116115Z"
    }
   },
   "outputs": [],
   "source": [
    "# def predict_sentiment(sentence):\n",
    "#     model.eval()\n",
    "#     tokens = tokenizer.tokenize(sentence)\n",
    "#     tokens = tokens[:max_input_length-2]\n",
    "#     indexed = [TOKEN_IDX['INIT']] + tokenizer.convert_tokens_to_ids(tokens) + [TOKEN_IDX['EOS']]\n",
    "#     tensor = torch.LongTensor(indexed).to(device)\n",
    "#     tensor = tensor.unsqueeze(0)\n",
    "#     prediction = torch.sigmoid(model(tensor))\n",
    "#     return prediction.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8932d42c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-12T00:09:01.116854Z",
     "start_time": "2022-09-12T00:09:01.116845Z"
    }
   },
   "outputs": [],
   "source": [
    "# predict_sentiment(\"This film is great\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35c48dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('abhienv': conda)",
   "language": "python",
   "name": "python397jvsc74a57bd0d1ae24538bb1d851c093f65f521db9490bc3625a505a8cd99441287c2dc17332"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
